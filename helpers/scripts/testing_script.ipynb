{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Sequence Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mczeneszew/Desktop/FLIPv3/helpers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sequence database:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'Variants': 'VDGV', 'HD': 0, 'Count input': 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.061910</td>\n",
       "      <td>{'Variants': 'ADGV', 'HD': 1, 'Count input': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.242237</td>\n",
       "      <td>{'Variants': 'CDGV', 'HD': 1, 'Count input': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>{'Variants': 'DDGV', 'HD': 1, 'Count input': 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>{'Variants': 'EDGV', 'HD': 1, 'Count input': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.377101</td>\n",
       "      <td>{'Variants': 'FDGV', 'HD': 1, 'Count input': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>{'Variants': 'GDGV', 'HD': 1, 'Count input': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>{'Variants': 'HDGV', 'HD': 1, 'Count input': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>1.445905</td>\n",
       "      <td>{'Variants': 'IDGV', 'HD': 1, 'Count input': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>{'Variants': 'KDGV', 'HD': 1, 'Count input': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence    target  \\\n",
       "0  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  1.000000   \n",
       "1  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.061910   \n",
       "2  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.242237   \n",
       "3  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.006472   \n",
       "4  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.032719   \n",
       "5  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.377101   \n",
       "6  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.008298   \n",
       "7  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.026480   \n",
       "8  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  1.445905   \n",
       "9  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.020161   \n",
       "\n",
       "                                         annotations  \n",
       "0  {'Variants': 'VDGV', 'HD': 0, 'Count input': 9...  \n",
       "1  {'Variants': 'ADGV', 'HD': 1, 'Count input': 3...  \n",
       "2  {'Variants': 'CDGV', 'HD': 1, 'Count input': 8...  \n",
       "3  {'Variants': 'DDGV', 'HD': 1, 'Count input': 6...  \n",
       "4  {'Variants': 'EDGV', 'HD': 1, 'Count input': 8...  \n",
       "5  {'Variants': 'FDGV', 'HD': 1, 'Count input': 1...  \n",
       "6  {'Variants': 'GDGV', 'HD': 1, 'Count input': 8...  \n",
       "7  {'Variants': 'HDGV', 'HD': 1, 'Count input': 4...  \n",
       "8  {'Variants': 'IDGV', 'HD': 1, 'Count input': 4...  \n",
       "9  {'Variants': 'KDGV', 'HD': 1, 'Count input': 2...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sequence_database import SequenceDatabase, read_csv_to_sequencedatabase\n",
    "\n",
    "csv_path = 'four_mutations_small.csv'\n",
    "seq_db = read_csv_to_sequencedatabase(csv_path)\n",
    "\n",
    "print(\"Loaded sequence database:\")\n",
    "display(seq_db.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of seq_db.sequences: <class 'list'>\n",
      "First sequence in seq_db.sequences: [[-1. -1. -2. ... -1. -1.  1.]\n",
      " [-1.  1.  0. ... -2. -1. -2.]\n",
      " [-2. -2. -2. ...  2.  7. -1.]\n",
      " ...\n",
      " [-2.  0.  1. ... -2.  2. -3.]\n",
      " [-2.  0.  1. ... -2.  2. -3.]\n",
      " [-2.  0.  1. ... -2.  2. -3.]]\n",
      "Type of first sequence: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of seq_db.sequences:\", type(seq_db.sequences))\n",
    "print(\"First sequence in seq_db.sequences:\", seq_db.sequences[0])\n",
    "print(\"Type of first sequence:\", type(seq_db.sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sequences (BLOSUM62):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]]),\n",
       " array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
       "        [-1.,  1.,  0., ..., -2., -1., -2.],\n",
       "        [-2., -2., -2., ...,  2.,  7., -1.],\n",
       "        ...,\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
       "        [-2.,  0.,  1., ..., -2.,  2., -3.]])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Encoded sequences (BLOSUM62):\")\n",
    "display(seq_db.sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0619096557142,\n",
       " 0.242237277886,\n",
       " 0.00647208961971,\n",
       " 0.0327191845926,\n",
       " 0.377100728425,\n",
       " 0.00829790573568,\n",
       " 0.0264798489707,\n",
       " 1.4459050863,\n",
       " 0.0201606557734]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Targets:\")\n",
    "display(seq_db.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Variants': 'VDGV',\n",
       "  'HD': 0,\n",
       "  'Count input': 92735,\n",
       "  'Count selected': 338346,\n",
       "  'keep': True,\n",
       "  'one_vs_rest': 'train',\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': 'train',\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': 'train',\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': 'train',\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': 'test',\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'ADGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 34,\n",
       "  'Count selected': 43,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'CDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 850,\n",
       "  'Count selected': 641,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'DDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 63,\n",
       "  'Count selected': 63,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'EDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 841,\n",
       "  'Count selected': 190,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'FDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 136,\n",
       "  'Count selected': 161,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'GDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 859,\n",
       "  'Count selected': 155,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'HDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 452,\n",
       "  'Count selected': 60,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'IDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 405,\n",
       "  'Count selected': 1460,\n",
       "  'keep': True,\n",
       "  'one_vs_rest': 'train',\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': 'train',\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': 'train',\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': 'train',\n",
       "  'sampled_validation': True,\n",
       "  'low_vs_high': 'test',\n",
       "  'low_vs_high_validation': nan},\n",
       " {'Variants': 'KDGV',\n",
       "  'HD': 1,\n",
       "  'Count input': 2585,\n",
       "  'Count selected': 323,\n",
       "  'keep': False,\n",
       "  'one_vs_rest': nan,\n",
       "  'one_vs_rest_validation': nan,\n",
       "  'two_vs_rest': nan,\n",
       "  'two_vs_rest_validation': nan,\n",
       "  'three_vs_rest': nan,\n",
       "  'three_vs_rest_validation': nan,\n",
       "  'sampled': nan,\n",
       "  'sampled_validation': nan,\n",
       "  'low_vs_high': nan,\n",
       "  'low_vs_high_validation': nan}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Annotations:\")\n",
    "display(seq_db.annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Dataloader  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ProteinDataset: 10\n",
      "First item in ProteinDataset: (array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
      "       [-1.,  1.,  0., ..., -2., -1., -2.],\n",
      "       [-2., -2., -2., ...,  2.,  7., -1.],\n",
      "       ...,\n",
      "       [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
      "       [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
      "       [-2.,  0.,  1., ..., -2.,  2., -3.]]), 1.0)\n",
      "Created DataLoader:\n",
      "torch.Size([10, 265, 20]) tensor([265, 265, 265, 265, 265, 265, 265, 265, 265, 265]) tensor([0.0202, 0.0327, 0.2422, 1.4459, 0.0083, 0.0265, 0.0619, 0.3771, 1.0000,\n",
      "        0.0065])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sequence_database import SequenceDatabase, read_csv_to_sequencedatabase\n",
    "from dataloader import create_dataloader, ProteinDataset\n",
    "import numpy as np\n",
    "\n",
    "protein_dataset = ProteinDataset(seq_db)\n",
    "print(f\"Length of ProteinDataset: {len(protein_dataset)}\")\n",
    "print(f\"First item in ProteinDataset: {protein_dataset[0]}\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Creating the DataLoader\n",
    "dataloader = create_dataloader(protein_dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"Created DataLoader:\")\n",
    "# for inputs, labels in dataloader:\n",
    "#     display(inputs, labels)\n",
    "for inputs, lengths, labels in dataloader:\n",
    "    print(inputs.shape, lengths, labels)\n",
    "    break  # Only printing the first batch \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 1, Loss: 0.31568026542663574\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 2, Loss: 4.036042213439941\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 3, Loss: 0.26327812671661377\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 4, Loss: 0.4347633421421051\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 5, Loss: 0.38021132349967957\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 6, Loss: 0.259596049785614\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 7, Loss: 0.22967281937599182\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 8, Loss: 0.27046653628349304\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 9, Loss: 0.24053482711315155\n",
      "Input shape: torch.Size([10, 265, 20])\n",
      "Epoch 10, Loss: 0.22196345031261444\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/32dn15tx2w90m2l4r4vkjcpc0000gp/T/ipykernel_76106/2751428894.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype=torch.float32)\n",
      "/var/folders/_q/32dn15tx2w90m2l4r4vkjcpc0000gp/T/ipykernel_76106/2751428894.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lengths = torch.tensor(lengths, dtype=torch.float32)\n",
      "/var/folders/_q/32dn15tx2w90m2l4r4vkjcpc0000gp/T/ipykernel_76106/2751428894.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models_flip import ConvNet\n",
    "\n",
    "input_size = protein_dataset[0][0].shape[0]  \n",
    "sequence_length = protein_dataset[0][0].shape[1]  # Getting the sequence length from data \n",
    "\n",
    "cnn_model = ConvNet(input_size=input_size, sequence_length=sequence_length)\n",
    "\n",
    "# Defining loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Now, we can train the model\n",
    "cnn_model.train()\n",
    "for epoch in range(10):  # Setting number of epochs \n",
    "    for inputs, lengths, labels in dataloader:\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        lengths = torch.tensor(lengths, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        print(\"Input shape:\", inputs.shape)  # Debug print\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs, lengths)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))  # Ensuring labels match output shape\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.5: Training the CNN model on sequences of different lengths   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sequence database:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>target</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'Variants': 'VDGV', 'HD': 0, 'Count input': 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.061910</td>\n",
       "      <td>{'Variants': 'ADGV', 'HD': 1, 'Count input': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.242237</td>\n",
       "      <td>{'Variants': 'CDGV', 'HD': 1, 'Count input': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>{'Variants': 'DDGV', 'HD': 1, 'Count input': 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>{'Variants': 'EDGV', 'HD': 1, 'Count input': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.377101</td>\n",
       "      <td>{'Variants': 'FDGV', 'HD': 1, 'Count input': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.008298</td>\n",
       "      <td>{'Variants': 'GDGV', 'HD': 1, 'Count input': 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>{'Variants': 'HDGV', 'HD': 1, 'Count input': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>1.445905</td>\n",
       "      <td>{'Variants': 'IDGV', 'HD': 1, 'Count input': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>{'Variants': 'KDGV', 'HD': 1, 'Count input': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence    target  \\\n",
       "0  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  1.000000   \n",
       "1  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.061910   \n",
       "2  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.242237   \n",
       "3  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.006472   \n",
       "4  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.032719   \n",
       "5  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.377101   \n",
       "6  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.008298   \n",
       "7  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.026480   \n",
       "8  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  1.445905   \n",
       "9  [[-1.0, -1.0, -2.0, -3.0, -1.0, 0.0, -2.0, -3....  0.020161   \n",
       "\n",
       "                                         annotations  \n",
       "0  {'Variants': 'VDGV', 'HD': 0, 'Count input': 9...  \n",
       "1  {'Variants': 'ADGV', 'HD': 1, 'Count input': 3...  \n",
       "2  {'Variants': 'CDGV', 'HD': 1, 'Count input': 8...  \n",
       "3  {'Variants': 'DDGV', 'HD': 1, 'Count input': 6...  \n",
       "4  {'Variants': 'EDGV', 'HD': 1, 'Count input': 8...  \n",
       "5  {'Variants': 'FDGV', 'HD': 1, 'Count input': 1...  \n",
       "6  {'Variants': 'GDGV', 'HD': 1, 'Count input': 8...  \n",
       "7  {'Variants': 'HDGV', 'HD': 1, 'Count input': 4...  \n",
       "8  {'Variants': 'IDGV', 'HD': 1, 'Count input': 4...  \n",
       "9  {'Variants': 'KDGV', 'HD': 1, 'Count input': 2...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sequence_database import SequenceDatabase, read_csv_to_sequencedatabase\n",
    "\n",
    "csv_path = 'four_mutations_random_lengths.csv'\n",
    "seq_db = read_csv_to_sequencedatabase(csv_path)\n",
    "\n",
    "print(\"Loaded sequence database:\")\n",
    "display(seq_db.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ProteinDataset: 10\n",
      "First item in ProteinDataset: (array([[-1., -1., -2., ..., -1., -1.,  1.],\n",
      "       [-1.,  1.,  0., ..., -2., -1., -2.],\n",
      "       [-2., -2., -2., ...,  2.,  7., -1.],\n",
      "       ...,\n",
      "       [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
      "       [-2.,  0.,  1., ..., -2.,  2., -3.],\n",
      "       [-2.,  0.,  1., ..., -2.,  2., -3.]]), 1.0)\n",
      "Created DataLoader:\n",
      "torch.Size([10, 264, 20]) tensor([264, 264, 264, 264, 264, 264, 264, 264, 264, 264]) tensor([0.0265, 0.0327, 0.0202, 0.0065, 1.0000, 0.0619, 0.0083, 0.2422, 1.4459,\n",
      "        0.3771])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sequence_database import SequenceDatabase, read_csv_to_sequencedatabase\n",
    "from dataloader import create_dataloader, ProteinDataset\n",
    "import numpy as np\n",
    "\n",
    "protein_dataset = ProteinDataset(seq_db)\n",
    "print(f\"Length of ProteinDataset: {len(protein_dataset)}\")\n",
    "print(f\"First item in ProteinDataset: {protein_dataset[0]}\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Creating the DataLoader\n",
    "dataloader = create_dataloader(protein_dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"Created DataLoader:\")\n",
    "# for inputs, labels in dataloader:\n",
    "#     display(inputs, labels)\n",
    "for inputs, lengths, labels in dataloader:\n",
    "    print(inputs.shape, lengths, labels)\n",
    "    break  # Only printing the first batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3422932028770447\n",
      "Epoch 2, Loss: 255.3261260986328\n",
      "Epoch 3, Loss: 0.3548205494880676\n",
      "Epoch 4, Loss: 11.793645858764648\n",
      "Epoch 5, Loss: 11.287260055541992\n",
      "Epoch 6, Loss: 8.27104663848877\n",
      "Epoch 7, Loss: 5.033824920654297\n",
      "Epoch 8, Loss: 2.385737895965576\n",
      "Epoch 9, Loss: 0.8384689092636108\n",
      "Epoch 10, Loss: 0.2522497773170471\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models_flip import ConvNet\n",
    "\n",
    "input_size = protein_dataset[0][0].shape[1]  # Number of features per amino acid\n",
    "sequence_length = max([len(seq) for seq in seq_db.sequences])  # Maximum sequence length in the dataset\n",
    "cnn_model = ConvNet(input_size=input_size, sequence_length=sequence_length)\n",
    "\n",
    "# Defining the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "cnn_model.train()\n",
    "# for epoch in range(10):  # Setting number of epochs\n",
    "#     for inputs, lengths, labels in dataloader:\n",
    "#         inputs = inputs.float().transpose(1, 2) \n",
    "#         labels = labels.float().unsqueeze(1)  \n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = cnn_model(inputs, lengths)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):  # Iterate through a fixed number of epochs\n",
    "    epoch_loss = 0.0  # To accumulate the loss over an epoch\n",
    "    \n",
    "    for inputs, lengths, labels in dataloader:\n",
    "        # Convert inputs to float32 and transpose to shape (batch_size, channels, sequence_length)\n",
    "        inputs = inputs.float().transpose(1, 2)\n",
    "        \n",
    "        # Convert labels to float32 and add an extra dimension to match the model's output shape\n",
    "        labels = labels.float().unsqueeze(1)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute the model output\n",
    "        outputs = cnn_model(inputs, lengths)\n",
    "\n",
    "        # Compute the loss between the model output and the true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss for the current batch\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss for the current epoch\n",
    "    average_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {average_loss}')\n",
    "\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training the Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "encoded_sequences_flattened = [seq.flatten() for seq in encoded_sequences]\n",
    "ridge_model.fit(encoded_sequences_flattened, targets)\n",
    "predictions = ridge_model.predict(encoded_sequences_flattened)\n",
    "mse = np.mean((predictions - targets) ** 2)\n",
    "print(f'Ridge Regression MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from cuml.linear_model import Ridge\n",
    "\n",
    "# Simplified dataset for testing\n",
    "encoded_sequences_flattened = np.array([seq.flatten()[:100] for seq in seq_db.sequences])\n",
    "\n",
    "# Converting numpy arrays to cupy arrays for GPU processing\n",
    "encoded_sequences_flattened = cp.asarray(encoded_sequences_flattened, dtype=cp.float32)\n",
    "targets = cp.asarray(seq_db.targets, dtype=cp.float32)\n",
    "\n",
    "# Checking the shapes and data types\n",
    "print(\"Encoded sequences shape:\", encoded_sequences_flattened.shape)\n",
    "print(\"Encoded sequences dtype:\", encoded_sequences_flattened.dtype)\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "print(\"Targets dtype:\", targets.dtype)\n",
    "\n",
    "# Initializing the Ridge Regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "\n",
    "# Fitting the model\n",
    "try:\n",
    "    ridge_model.fit(encoded_sequences_flattened, targets)\n",
    "except Exception as e:\n",
    "    print(\"Error during fitting:\", e)\n",
    "\n",
    "# Predicting the targets\n",
    "try:\n",
    "    predictions = ridge_model.predict(encoded_sequences_flattened)\n",
    "    predictions = cp.asnumpy(predictions)\n",
    "    targets = cp.asnumpy(targets)\n",
    "\n",
    "    # Calculating the Mean Squared Error (MSE)\n",
    "    mse = np.mean((predictions - targets) ** 2)\n",
    "    print(f'Ridge Regression MSE: {mse}')\n",
    "except Exception as e:\n",
    "    print(\"Error during prediction:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flip_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
